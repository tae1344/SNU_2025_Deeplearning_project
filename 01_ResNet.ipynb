{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe79beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_seed 42\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "CUDA device count: 0\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, math, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from common.config import (\n",
    "    BASE_DIR,\n",
    "    NUM_CLASSES,\n",
    "    BATCH_SIZE,\n",
    "    EPOCHS,\n",
    "    WARMUP_EPOCHS,\n",
    "    SEED,\n",
    "    BASE_LEARNING_RATE,\n",
    "    WD,\n",
    "    SEED,\n",
    "    DEVICE,\n",
    "    WORKER_NUM,\n",
    "    CLASS_NAMES,\n",
    "    TRANSFORM,\n",
    "    TRAIN_IMAGE_DIR,\n",
    "    TRAIN_LABEL_DIR,\n",
    "    VAL_IMAGE_DIR,\n",
    "    VAL_LABEL_DIR,\n",
    "    TEST_IMAGE_DIR,\n",
    "    TEST_LABEL_DIR,\n",
    "    LOG_DIR,\n",
    "    TRAIN_LOG_DIR,\n",
    "    TEST_LOG_DIR,\n",
    "    MODEL_DIR,\n",
    "    DROPOUT_RATE,\n",
    ")\n",
    "from common.utils import (\n",
    "    set_seed,\n",
    "    worker_init_fn,\n",
    "    get_mean_std_from_weights,\n",
    "    get_device,\n",
    "    device_pretty,\n",
    "    human_time,\n",
    "    count_parameters,\n",
    "    calculate_top_k_accuracy,\n",
    "    calculate_f1_score,\n",
    "    calculate_auroc,\n",
    "    save_auroc_data,\n",
    "    save_checkpoint,\n",
    ")\n",
    "from common.dataset import CustomDataset\n",
    "from common.logger import Logger\n",
    "from common.evaluate import evaluate_test_set, print_test_results\n",
    "\n",
    "# initail seed 설정\n",
    "set_seed(SEED)\n",
    "\n",
    "# Check PyTorch version and CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "# Set device for computations\n",
    "device = torch.device(DEVICE)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8d214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/tykim/Desktop/work/SNU_2025_Deeplearning_project\n",
      "LABEL_DIR: /Users/tykim/Desktop/work/SNU_2025_Deeplearning_project/data/train/라벨링데이터\n",
      "IMAGE_DIR: /Users/tykim/Desktop/work/SNU_2025_Deeplearning_project/data/train/원천데이터\n",
      "LABEL_DIR exists: True\n",
      "IMAGE_DIR exists: True\n",
      "Found json files: 12000\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"LABEL_DIR:\", TRAIN_LABEL_DIR)\n",
    "print(\"IMAGE_DIR:\", TRAIN_IMAGE_DIR)\n",
    "print(\"LABEL_DIR exists:\", os.path.isdir(TRAIN_LABEL_DIR))\n",
    "print(\"IMAGE_DIR exists:\", os.path.isdir(TRAIN_IMAGE_DIR))\n",
    "\n",
    "json_paths = glob.glob(os.path.join(TRAIN_LABEL_DIR, \"**\", \"*.json\"), recursive=True)\n",
    "print(\"Found json files:\", len(json_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd729a41",
   "metadata": {},
   "source": [
    "# 1. 데이터 셋 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31a4244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 12000/12000 [01:39<00:00, 121.11file/s]\n",
      "Loading data: 100%|██████████| 1500/1500 [00:13<00:00, 113.55file/s]\n",
      "Loading data: 100%|██████████| 1500/1500 [00:13<00:00, 111.46file/s]\n"
     ]
    }
   ],
   "source": [
    "# 1) 데이터 증강,변환(색 왜곡은 과하지 않게)\n",
    "MODEL_FILE_NAME = \"best_restnet_model.pth\"\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    label_folder=TRAIN_LABEL_DIR, image_folder=TRAIN_IMAGE_DIR, transform=TRANSFORM\n",
    ")\n",
    "val_datatset = CustomDataset(\n",
    "    label_folder=VAL_LABEL_DIR, image_folder=VAL_IMAGE_DIR, transform=TRANSFORM\n",
    ")\n",
    "test_datatset = CustomDataset(\n",
    "    label_folder=TEST_LABEL_DIR, image_folder=TEST_IMAGE_DIR, transform=TRANSFORM\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=WORKER_NUM,\n",
    "    generator=torch.Generator(device=DEVICE),\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_datatset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKER_NUM,\n",
    "    generator=torch.Generator(device=DEVICE),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    val_datatset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=WORKER_NUM,\n",
    "    generator=torch.Generator(device=DEVICE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607b3b7",
   "metadata": {},
   "source": [
    "# 2. 모델 설정 - ResNet101\n",
    "\n",
    "## 각 모델별로 다르게 설정!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36b97c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=2048, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 모델: ResNet101 - CNN 기반 모델\n",
    "def create_model():\n",
    "    weights = models.ResNet101_Weights.IMAGENET1K_V2\n",
    "    model = models.resnet101(weights=weights)\n",
    "\n",
    "    # 기존 분류기의 입력 차원 수 가져옴 (2048개)\n",
    "    in_feats = model.fc.in_features\n",
    "\n",
    "    # 마지막 분류기 교체: 입력 → 출력 선형 변환, 2048 → 15개\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(p=DROPOUT_RATE), nn.Linear(in_feats, NUM_CLASSES)\n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "model = create_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c0710",
   "metadata": {},
   "source": [
    "# 3. Optima, Scheduler, Scaler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced8239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Mixed Precision Training disabled (CPU mode)\n"
     ]
    }
   ],
   "source": [
    "# 3) 손실/옵티마/스케줄러\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=BASE_LEARNING_RATE, weight_decay=WD\n",
    ")\n",
    "\n",
    "def lr_lambda(current_epoch):\n",
    "    if current_epoch < WARMUP_EPOCHS:\n",
    "        return float(current_epoch + 1) / WARMUP_EPOCHS\n",
    "    # cosine\n",
    "    t = (current_epoch - WARMUP_EPOCHS) / max(1, (EPOCHS - WARMUP_EPOCHS))\n",
    "    return 0.5 * (1 + math.cos(math.pi * t))\n",
    "\n",
    "\n",
    "# 스케쥴러\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "# 스케일러\n",
    "# Mixed Precision Training 설정 (GPU에서만 사용)\n",
    "if torch.cuda.is_available():\n",
    "    scaler = torch.amp.GradScaler(\"cuda\")\n",
    "    print(\"✅ Mixed Precision Training enabled (GPU)\")\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"⚠️  Mixed Precision Training disabled (CPU mode)\")\n",
    "\n",
    "# Logger 설정\n",
    "logger = Logger(LOG_DIR, \"train_log.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ea90a",
   "metadata": {},
   "source": [
    "# 4. 평가지표 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefd6276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started at 2025-09-04 02:04:08\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_top3_accuracies, val_top3_accuracies = [], []\n",
    "train_aurocs, val_aurocs = [], []\n",
    "train_f1_scores, val_f1_scores = [], []\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_composite_score = 0.0  # 복합 점수 초기화\n",
    "best_epoch = 0\n",
    "early_stopping_counter = 0\n",
    "patience = 20\n",
    "\n",
    "# 학습 시작 시간\n",
    "total_start_time = time.time()\n",
    "print(\n",
    "    f\"Training started at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(total_start_time))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b3893",
   "metadata": {},
   "source": [
    "# 5. 모델 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b7dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model, train_loader, criterion, optimizer, device, scaler=None, desc=None\n",
    "):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_correct = 0\n",
    "    epoch_top3_correct = 0\n",
    "    epoch_total = 0\n",
    "\n",
    "    train_outputs = []\n",
    "    train_labels = []\n",
    "\n",
    "    iterator = train_loader\n",
    "    if desc is not None:\n",
    "        try:\n",
    "            from tqdm.auto import tqdm\n",
    "\n",
    "            iterator = tqdm(train_loader, desc=desc)\n",
    "        except Exception:\n",
    "            iterator = train_loader\n",
    "\n",
    "    for images, labels in iterator:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scaler is not None:\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        batch_size = labels.size(0)\n",
    "        epoch_total += batch_size\n",
    "        epoch_correct += (preds == labels).sum().item()\n",
    "        epoch_top3_correct += calculate_top_k_accuracy(outputs, labels, k=3)\n",
    "\n",
    "        train_outputs.extend(outputs.detach().cpu().tolist())\n",
    "        train_labels.extend(labels.detach().cpu().tolist())\n",
    "\n",
    "    epoch_loss /= max(1, len(train_loader))\n",
    "    epoch_acc = epoch_correct / max(1, epoch_total)\n",
    "    epoch_top3_acc = epoch_top3_correct / max(1, epoch_total)\n",
    "\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"accuracy\": epoch_acc,\n",
    "        \"top3_accuracy\": epoch_top3_acc,\n",
    "        \"outputs\": train_outputs,\n",
    "        \"labels\": train_labels,\n",
    "    }\n",
    "\n",
    "\n",
    "def validation_one_epoch(model, val_loader, criterion, device, desc=None):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_top3_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "\n",
    "    iterator = val_loader\n",
    "    if desc is not None:\n",
    "        try:\n",
    "            from tqdm.auto import tqdm\n",
    "\n",
    "            iterator = tqdm(val_loader, desc=desc)\n",
    "        except Exception:\n",
    "            iterator = val_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in iterator:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            batch_size = labels.size(0)\n",
    "            val_total += batch_size\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_top3_correct += calculate_top_k_accuracy(outputs, labels, k=3)\n",
    "\n",
    "            val_outputs.extend(outputs.detach().cpu().tolist())\n",
    "            val_labels.extend(labels.detach().cpu().tolist())\n",
    "\n",
    "    val_loss /= max(1, len(val_loader))\n",
    "    val_acc = val_correct / max(1, val_total)\n",
    "    val_top3_acc = val_top3_correct / max(1, val_total)\n",
    "\n",
    "    return {\n",
    "        \"loss\": val_loss,\n",
    "        \"accuracy\": val_acc,\n",
    "        \"top3_accuracy\": val_top3_acc,\n",
    "        \"outputs\": val_outputs,\n",
    "        \"labels\": val_labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57c791",
   "metadata": {},
   "source": [
    "# 6. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa2d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd14679c44647218362f072f658cd21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1/1:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()  # 에포크 시작 시간 기록\n",
    "\n",
    "    # ===============================================\n",
    "    # Training\n",
    "    # ===============================================\n",
    "    train_metrics = train_one_epoch(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        scaler=scaler,\n",
    "        desc=f\"Training Epoch {epoch+1}/{EPOCHS}\",\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_metrics[\"loss\"])\n",
    "    train_accuracies.append(train_metrics[\"accuracy\"])\n",
    "    train_top3_accuracies.append(train_metrics[\"top3_accuracy\"])\n",
    "    train_f1_scores.append(\n",
    "        calculate_f1_score(\n",
    "            torch.tensor(train_metrics[\"outputs\"]),\n",
    "            torch.tensor(train_metrics[\"labels\"]),\n",
    "        )\n",
    "    )\n",
    "    train_aurocs.append(\n",
    "        calculate_auroc(\n",
    "            torch.tensor(train_metrics[\"outputs\"]),\n",
    "            torch.tensor(train_metrics[\"labels\"]),\n",
    "        )\n",
    "    )\n",
    "    save_auroc_data(\n",
    "        train_metrics[\"outputs\"],\n",
    "        train_metrics[\"labels\"],\n",
    "        epoch + 1,\n",
    "        \"train\",\n",
    "        TRAIN_LOG_DIR,\n",
    "    )\n",
    "\n",
    "    # ===============================================\n",
    "    # Validation\n",
    "    # ===============================================\n",
    "    val_metrics = validation_one_epoch(\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        desc=\"Validating\",\n",
    "    )\n",
    "\n",
    "    val_losses.append(val_metrics[\"loss\"])\n",
    "    val_accuracies.append(val_metrics[\"accuracy\"])\n",
    "    val_top3_accuracies.append(val_metrics[\"top3_accuracy\"])\n",
    "    val_f1_scores.append(\n",
    "        calculate_f1_score(torch.tensor(val_metrics[\"outputs\"]), torch.tensor(val_metrics[\"labels\"]))\n",
    "    )\n",
    "    val_aurocs.append(\n",
    "        calculate_auroc(torch.tensor(val_metrics[\"outputs\"]), torch.tensor(val_metrics[\"labels\"]))\n",
    "    )\n",
    "    save_auroc_data(val_metrics[\"outputs\"], val_metrics[\"labels\"], epoch + 1, \"val\", TRAIN_LOG_DIR)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step()  # ReduceLROnPlateau 사용 시: scheduler.step(val_metrics[\"loss\"])\n",
    "\n",
    "    # 에포크 소요 시간 계산\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "\n",
    "    # 에포크 결과 출력\n",
    "    print(\n",
    "        f\"[Epoch {epoch+1}/{EPOCHS}] \"\n",
    "        f\"Time: {epoch_duration:.2f}s, \"\n",
    "        f\"Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracies[-1]:.4f}, Train Top-3: {train_top3_accuracies[-1]:.4f}, Train F1: {train_f1_scores[-1]:.4f}, \"\n",
    "        f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.4f}, Val Top-3: {val_top3_accuracies[-1]:.4f}, Val F1: {val_f1_scores[-1]:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 의료 이미지 분류에 최적화된 복합 점수 계산\n",
    "    composite_score = (\n",
    "        0.4 * val_accuracies[-1] +      # 40% - 정확도 (가장 중요)\n",
    "        0.3 * val_aurocs[-1] +          # 30% - AUROC (의료 분류에서 중요)\n",
    "        0.2 * val_f1_scores[-1] +       # 20% - F1 Score (클래스 불균형 고려)\n",
    "        0.1 * (1 - val_losses[-1])      # 10% - Loss (낮을수록 좋음)\n",
    "    )\n",
    "\n",
    "    # 최고 성능 모델 저장\n",
    "    if composite_score > best_composite_score:\n",
    "        best_composite_score = composite_score\n",
    "        best_epoch = epoch + 1\n",
    "        early_stopping_counter = 0\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,  # 현재 에포크\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"train_loss\": train_losses[-1],\n",
    "                \"train_accuracy\": train_accuracies[-1],\n",
    "                \"train_top3_accuracy\": train_top3_accuracies[-1],\n",
    "                \"train_f1_score\": train_f1_scores[-1],\n",
    "                \"train_auroc\": train_aurocs[-1],\n",
    "                \"val_loss\": val_losses[-1],\n",
    "                \"val_accuracy\": val_accuracies[-1],\n",
    "                \"val_top3_accuracy\": val_top3_accuracies[-1],\n",
    "                \"val_f1_score\": val_f1_scores[-1],\n",
    "                \"val_auroc\": val_aurocs[-1],\n",
    "                \"composite_score\": composite_score,\n",
    "                \"epoch_duration\": epoch_duration,\n",
    "            },\n",
    "            MODEL_DIR,\n",
    "            MODEL_FILE_NAME,\n",
    "        )\n",
    "        print(f\"🎯 New best model saved! Composite Score: {composite_score:.4f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}. Best epoch was {best_epoch}.\")\n",
    "        break\n",
    "\n",
    "    # 로그 기록\n",
    "    logger.log(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_losses[-1],\n",
    "            \"train_accuracy\": train_accuracies[-1],\n",
    "            \"train_top3_accuracy\": train_top3_accuracies[-1],\n",
    "            \"train_f1_score\": train_f1_scores[-1],\n",
    "            \"train_auroc\": train_aurocs[-1],\n",
    "            \"val_loss\": val_losses[-1],\n",
    "            \"val_accuracy\": val_accuracies[-1],\n",
    "            \"val_top3_accuracy\": val_top3_accuracies[-1],\n",
    "            \"val_f1_score\": val_f1_scores[-1],\n",
    "            \"val_auroc\": val_aurocs[-1],\n",
    "            \"composite_score\": composite_score,\n",
    "            \"epoch_duration\": epoch_duration,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 저장\n",
    "logger.save()\n",
    "\n",
    "# 학습 종료 시간\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "print(\n",
    "    f\"Training completed at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(total_end_time))}\"\n",
    ")\n",
    "print(f\"Total training time: {total_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b1222",
   "metadata": {},
   "source": [
    "# 7. Test 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b692bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 로드\n",
    "checkpoint = torch.load(os.path.join(MODEL_DIR, MODEL_FILE_NAME), weights_only=False)\n",
    "\n",
    "# 체크포인트의 키들 확인\n",
    "print(\"Checkpoint keys:\", list(checkpoint.keys()))\n",
    "print(\"State dict keys (first 10):\", list(checkpoint[\"state_dict\"].keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e010b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 (기존 모델 정의 코드 필요)\n",
    "model = create_model()\n",
    "\n",
    "# 체크포인트에서 가중치 로드\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "# 평가 실행\n",
    "results = evaluate_test_set(model, test_loader, criterion, device)\n",
    "print_test_results(results, \"ResNet-101\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taeya_python_env3.13",
   "language": "python",
   "name": "taeya_python_env3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
